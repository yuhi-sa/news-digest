"""Article summarization (pluggable strategy)."""

from __future__ import annotations

import html
import json
import logging
import re
import urllib.request
from abc import ABC, abstractmethod
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import replace

from .parser import Article

logger = logging.getLogger(__name__)

_MAX_BODY_CHARS = 3000


def _fetch_page_text(url: str, timeout: int = 15) -> str:
    """Fetch a URL and return plain text extracted from HTML.

    Returns empty string on any failure.
    """
    try:
        req = urllib.request.Request(
            url,
            headers={"User-Agent": "NewsDigestBot/1.0"},
        )
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            raw = resp.read().decode("utf-8", errors="replace")
    except Exception:
        logger.debug("Failed to fetch %s", url)
        return ""

    # Remove script/style blocks, then strip all tags
    text = re.sub(r"<(script|style)[^>]*>.*?</\1>", "", raw, flags=re.S | re.I)
    text = re.sub(r"<[^>]+>", " ", text)
    text = html.unescape(text)
    text = re.sub(r"\s+", " ", text).strip()
    return text[:_MAX_BODY_CHARS]


def _fetch_pages_parallel(
    urls: list[str], max_workers: int = 6,
) -> dict[str, str]:
    """Fetch multiple URLs in parallel. Returns {url: text}."""
    results: dict[str, str] = {}
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_url = {
            executor.submit(_fetch_page_text, url): url for url in urls
        }
        for future in as_completed(future_to_url):
            url = future_to_url[future]
            try:
                results[url] = future.result()
            except Exception:
                results[url] = ""
    return results

_PROMPT_TEMPLATE = (
    "ä»¥ä¸‹ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨æ¦‚è¦ã‚’èª­ã‚“ã§ã€æ—¥æœ¬èªã§1ã€œ2æ–‡ã®ç°¡æ½”ãªè¦ç´„ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚"
    "è¦ç´„ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚\n\n"
    "ã‚¿ã‚¤ãƒˆãƒ«: {title}\n"
    "æ¦‚è¦: {summary}"
)

_BATCH_PROMPT_TEMPLATE = (
    "ä»¥ä¸‹ã®è¤‡æ•°ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«ã¤ã„ã¦ã€ãã‚Œãã‚Œæ—¥æœ¬èªã§1ã€œ2æ–‡ã®ç°¡æ½”ãªè¦ç´„ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
    "å„è¦ç´„ã¯ç•ªå·ä»˜ãã§è¿”ã—ã¦ãã ã•ã„ï¼ˆä¾‹: 1. è¦ç´„æ–‡ï¼‰ã€‚\n"
    "è¦ç´„ã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚\n\n"
    "{articles}"
)


class Summarizer(ABC):
    """Base class for article summarizers."""

    @abstractmethod
    def summarize(self, articles: list[Article]) -> list[Article]:
        """Return articles with potentially updated summaries."""


class PassthroughSummarizer(Summarizer):
    """Uses RSS description as-is (no external API calls)."""

    def summarize(self, articles: list[Article]) -> list[Article]:
        logger.info("PassthroughSummarizer: keeping original summaries for %d articles", len(articles))
        return articles


class GeminiSummarizer(Summarizer):
    """Summarizes articles in Japanese using Google Gemini API (free tier)."""

    ENDPOINT = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent"

    def __init__(self, api_key: str):
        self.api_key = api_key

    def _call_gemini(self, prompt: str) -> str | None:
        """Call Gemini API and return the generated text."""
        url = f"{self.ENDPOINT}?key={self.api_key}"
        payload = json.dumps({
            "contents": [{"parts": [{"text": prompt}]}],
        }).encode("utf-8")

        req = urllib.request.Request(
            url,
            data=payload,
            headers={"Content-Type": "application/json"},
            method="POST",
        )

        try:
            with urllib.request.urlopen(req, timeout=60) as resp:
                data = json.loads(resp.read().decode("utf-8"))
            return data["candidates"][0]["content"]["parts"][0]["text"].strip()
        except Exception:
            logger.exception("Gemini API call failed")
            return None

    def _summarize_single(self, article: Article) -> Article:
        """Summarize a single article via Gemini API."""
        prompt = _PROMPT_TEMPLATE.format(title=article.title, summary=article.summary)
        ja_summary = self._call_gemini(prompt)
        if ja_summary:
            return replace(article, summary=ja_summary)
        logger.warning("Fallback to original summary for: %s", article.title)
        return article

    def _summarize_batch(self, batch: list[Article]) -> list[Article]:
        """Summarize a batch of articles in a single API call.

        Falls back to individual calls if the batch call fails.
        """
        articles_text = "\n".join(
            f"{i + 1}. ã‚¿ã‚¤ãƒˆãƒ«: {a.title}\n   æ¦‚è¦: {a.summary}"
            for i, a in enumerate(batch)
        )
        prompt = _BATCH_PROMPT_TEMPLATE.format(articles=articles_text)
        response = self._call_gemini(prompt)

        if response:
            summaries = self._parse_batch_response(response, len(batch))
            if summaries:
                results: list[Article] = []
                for article, summary in zip(batch, summaries):
                    results.append(replace(article, summary=summary))
                return results

        # Fallback: summarize individually
        logger.warning("Batch summarization failed, falling back to individual calls for %d articles", len(batch))
        return [self._summarize_single(a) for a in batch]

    @staticmethod
    def _parse_batch_response(response: str, expected_count: int) -> list[str] | None:
        """Parse numbered summaries from a batch response.

        Returns None if parsing fails or count doesn't match.
        """
        import re
        lines = response.strip().split("\n")
        summaries: list[str] = []
        current = ""
        for line in lines:
            match = re.match(r"^\d+[\.\)]\s*", line)
            if match:
                if current:
                    summaries.append(current.strip())
                current = line[match.end():]
            else:
                if current:
                    current += " " + line.strip()
        if current:
            summaries.append(current.strip())

        if len(summaries) == expected_count:
            return summaries
        logger.warning(
            "Batch response parse mismatch: expected %d, got %d",
            expected_count,
            len(summaries),
        )
        return None

    def summarize(self, articles: list[Article], batch_size: int = 5) -> list[Article]:
        logger.info("GeminiSummarizer: summarizing %d articles in Japanese (batch_size=%d)", len(articles), batch_size)
        results: list[Article] = []
        for i in range(0, len(articles), batch_size):
            batch = articles[i : i + batch_size]
            results.extend(self._summarize_batch(batch))
        return results

    # ------------------------------------------------------------------
    # Two-stage briefing
    # ------------------------------------------------------------------

    def _select_articles(self, articles: list[Article]) -> list[int]:
        """Stage 1: Ask Gemini to pick the most important article indices."""
        article_list = "\n".join(
            f"{i}. [{a.category}] {a.title}: {a.summary}"
            for i, a in enumerate(articles)
        )
        prompt = (
            "ã‚ãªãŸã¯ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å…¼æ—¥æœ¬æ ªãƒ»ç±³å›½æ ªã®å€‹äººæŠ•è³‡å®¶å‘ã‘ã®"
            "ã‚·ãƒ‹ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚\n"
            "ä»¥ä¸‹ã®è¨˜äº‹ä¸€è¦§ã‹ã‚‰ã€èª­è€…ã«ã¨ã£ã¦æœ¬å½“ã«é‡è¦ãªè¨˜äº‹ã‚’**10ã€œ15ä»¶**é¸ã‚“ã§ãã ã•ã„ã€‚\n\n"
            "## èª­è€…ã®æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯\n"
            "èª­è€…ã¯ä»¥ä¸‹ã®æŠ€è¡“ã‚’æ—¥å¸¸çš„ã«ä½¿ã†ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚"
            "ã“ã‚Œã‚‰ã«é–¢é€£ã™ã‚‹è¨˜äº‹ã¯å„ªå…ˆçš„ã«é¸ã‚“ã§ãã ã•ã„:\n"
            "- è¨€èª: TypeScript/Next.js, Python, Go, Spark\n"
            "- ã‚¤ãƒ³ãƒ•ãƒ©: Kubernetes, Kafka, MySQL, Cassandra, Redis, Hadoop, Athenz\n"
            "- ãƒ‡ãƒ¼ã‚¿åŸºç›¤: dbt, Airflow, Databricks, BigQuery, Athena\n\n"
            "## é¸å®šåŸºæº–\n"
            "- ä¸Šè¨˜ã‚¹ã‚¿ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹é‡è¦ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆãƒ»è„†å¼±æ€§ãƒ»ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹\n"
            "- æŠ€è¡“çš„ã«é‡è¦ï¼ˆAI/MLã€ãƒ‡ãƒ¼ã‚¿åŸºç›¤ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã®æ–°å‹•å‘ãƒ»è„†å¼±æ€§ï¼‰\n"
            "- æŠ•è³‡åˆ¤æ–­ã«ç›´çµï¼ˆãƒã‚¯ãƒ­æŒ‡æ¨™ã€æ±ºç®—ã€ã‚»ã‚¯ã‚¿ãƒ¼å‹•å‘ï¼‰\n"
            "- äº›æœ«ãªãƒ‹ãƒ¥ãƒ¼ã‚¹ã€å®£ä¼çš„ãªè¨˜äº‹ã€æ—¢çŸ¥ã®ç¹°ã‚Šè¿”ã—ã¯é™¤å¤–\n"
            "- æŠ€è¡“æƒ…å ±ã‚’å„ªå…ˆã€æŠ•è³‡æƒ…å ±ã¯ã‚µãƒ–\n\n"
            "## å‡ºåŠ›å½¢å¼\n"
            "é¸ã‚“ã è¨˜äº‹ã®ç•ªå·ã‚’JSONé…åˆ—ã§è¿”ã—ã¦ãã ã•ã„ã€‚ãã‚Œä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸è¦ã§ã™ã€‚\n"
            "ä¾‹: [0, 3, 7, 12, 15]\n\n"
            f"## è¨˜äº‹ä¸€è¦§ï¼ˆ{len(articles)}ä»¶ï¼‰\n\n"
            f"{article_list}"
        )
        logger.info("Stage 1: selecting important articles from %d candidates", len(articles))
        response = self._call_gemini(prompt)
        if not response:
            return []

        # Extract JSON array from response
        try:
            match = re.search(r"\[[\d\s,]+\]", response)
            if match:
                indices = json.loads(match.group())
                valid = [i for i in indices if 0 <= i < len(articles)]
                logger.info("Stage 1: selected %d articles", len(valid))
                return valid
        except (json.JSONDecodeError, ValueError):
            pass
        logger.warning("Stage 1: failed to parse selection response")
        return []

    def generate_briefing(self, articles: list[Article]) -> str | None:
        """Generate a curated daily briefing using two-stage approach.

        Stage 1: Select important articles from RSS summaries.
        Stage 2: Fetch full text of selected articles, then generate deep briefing.
        """
        # Stage 1: Select
        selected_indices = self._select_articles(articles)
        if not selected_indices:
            logger.warning("Stage 1 returned no articles, falling back to summary-only briefing")
            selected = articles[:15]
        else:
            selected = [articles[i] for i in selected_indices]

        # Fetch full text of selected articles
        urls = [a.link for a in selected if a.link]
        logger.info("Stage 2: fetching full text for %d selected articles", len(urls))
        page_texts = _fetch_pages_parallel(urls)
        fetched = sum(1 for t in page_texts.values() if t)
        logger.info("Stage 2: successfully fetched %d/%d pages", fetched, len(urls))

        # Build enriched article list
        enriched_parts: list[str] = []
        for a in selected:
            body = page_texts.get(a.link, "")
            entry = (
                f"### [{a.category}] {a.title}\n"
                f"- URL: {a.link}\n"
                f"- RSSæ¦‚è¦: {a.summary}\n"
            )
            if body:
                entry += f"- è¨˜äº‹æœ¬æ–‡ï¼ˆæŠœç²‹ï¼‰: {body}\n"
            enriched_parts.append(entry)
        enriched_text = "\n".join(enriched_parts)

        # Stage 2: Generate briefing with full context
        prompt = (
            "ã‚ãªãŸã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å…¼æ—¥æœ¬æ ªãƒ»ç±³å›½æ ªã®å€‹äººæŠ•è³‡å®¶å‘ã‘ã®"
            "ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚\n"
            "ä»¥ä¸‹ã®å³é¸ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ï¼ˆæœ¬æ–‡ä»˜ãï¼‰ã‚’åˆ†æã—ã€æ—¥æœ¬èªã§**ãƒ‡ã‚¤ãƒªãƒ¼ãƒ–ãƒªãƒ¼ãƒ•ã‚£ãƒ³ã‚°**ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
            "## èª­è€…ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«\n"
            "èª­è€…ã¯ä»¥ä¸‹ã®æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯ã‚’æ—¥å¸¸çš„ã«ä½¿ã†ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚"
            "è¨˜äº‹ã®è§£èª¬ã§ã¯ã€ã“ã‚Œã‚‰ã®æŠ€è¡“ã¨ã®é–¢é€£ãŒã‚ã‚Œã°ç©æ¥µçš„ã«è¨€åŠã—ã¦ãã ã•ã„:\n"
            "- è¨€èª: TypeScript/Next.js, Python, Go, Spark\n"
            "- ã‚¤ãƒ³ãƒ•ãƒ©: Kubernetes, Kafka, MySQL, Cassandra, Redis, Hadoop, Athenz\n"
            "- ãƒ‡ãƒ¼ã‚¿åŸºç›¤: dbt, Airflow, Databricks, BigQuery, Athena\n\n"
            "## æ–‡ç« ã‚¹ã‚¿ã‚¤ãƒ«\n\n"
            "- **ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ¬ã‚¿ãƒ¼ã®ã‚ˆã†ã«è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ–‡ä½“**ã§æ›¸ãã€‚ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç©´åŸ‹ã‚ã®ã‚ˆã†ãªæ©Ÿæ¢°çš„ãªæ–‡ç« ã¯é¿ã‘ã‚‹ã€‚\n"
            "- 1ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã¯**3ã€œ4è¡Œã§å®Œçµ**ã•ã›ã‚‹ã€‚é•·ã€…ã¨æ›¸ã‹ãªã„ã€‚\n"
            "- ã€Œâ†’ ãã‚ŒãŒæ„å‘³ã™ã‚‹ã“ã¨:ã€ã€Œâ†’ å®Ÿå‹™ã¸ã®å½±éŸ¿:ã€ã®ã‚ˆã†ãªå®šå‹ãƒ©ãƒ™ãƒ«ã¯ä½¿ã‚ãªã„ã€‚"
            "ä»£ã‚ã‚Šã«ã€äº‹å®Ÿã®èª¬æ˜ã‹ã‚‰è‡ªç„¶ã«ã€Œã¤ã¾ã‚Šã€œã€ã€Œãƒã‚¤ãƒ³ãƒˆã¯ã€œã€ã€Œæ³¨ç›®ã™ã¹ãã¯ã€œã€ã¨ç¹‹ã’ã‚‹ã€‚\n"
            "- 1æ–‡ã‚’çŸ­ãä¿ã¤ï¼ˆ40å­—ä»¥å†…ç›®å®‰ï¼‰ã€‚èª­ç‚¹ã§ç¹‹ã’ã™ããªã„ã€‚\n"
            "- åŒã˜è¨˜äº‹ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã¨å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§é‡è¤‡ã•ã›ãªã„ã€‚ãƒã‚¤ãƒ©ã‚¤ãƒˆã§è§¦ã‚ŒãŸã‚‚ã®ã¯å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯çœç•¥ã™ã‚‹ã€‚\n"
            "- é–¢é€£ã™ã‚‹è¤‡æ•°ã®è¨˜äº‹ã¯1ã¤ã®ãƒˆãƒ”ãƒƒã‚¯ã«ã¾ã¨ã‚ã¦è«–ã˜ã¦ã‚ˆã„ã€‚\n\n"
            "## ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ§‹æˆï¼ˆMarkdownï¼‰\n\n"
            "### `## ğŸ”¥ æœ¬æ—¥ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ`\n"
            "æœ€é‡è¦ã®3ä»¶ã€‚å„é …ç›®ã¯:\n"
            "- **å¤ªå­—ã®è¦‹å‡ºã—**ï¼ˆ1è¡Œï¼‰\n"
            "- ä½•ãŒèµ·ãã¦ã€ãªãœé‡è¦ã‹ï¼ˆ2ã€œ3æ–‡ã‚’è‡ªç„¶ã«ç¹‹ã’ã‚‹ï¼‰\n"
            "- ğŸ“ [è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«](URL)\n\n"
            "### `## ğŸ› ï¸ ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼`\n"
            "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ã—ã¦æŠ¼ã•ãˆã‚‹ã¹ããƒˆãƒ”ãƒƒã‚¯ã‚’2ã€œ4ä»¶ã€‚\n"
            "è¨˜äº‹æœ¬æ–‡ã‚’è¸ã¾ãˆã€ã€Œä½•ãŒæ–°ã—ã„ã®ã‹ãƒ»ãªãœé‡è¦ã‹ã€ã‚’ç°¡æ½”ã«ã€‚\n"
            "ğŸ“ ãƒªãƒ³ã‚¯ã‚’å„é …ç›®æœ«å°¾ã«ã€‚\n\n"
            "### `## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°`\n"
            "ãƒ‡ãƒ¼ã‚¿åŸºç›¤ãƒ»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–¢é€£ã€‚è©²å½“ãªã—ãªã‚‰çœç•¥ã€‚\n\n"
            "### `## ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£`\n"
            "è„†å¼±æ€§ãƒ»æ”»æ’ƒå‹•å‘ãƒ»å¯¾ç­–ã€‚è©²å½“ãªã—ãªã‚‰çœç•¥ã€‚\n"
            "CVEã¯å½±éŸ¿ç¯„å›²ã¨ç·Šæ€¥åº¦ã‚’æ˜è¨˜ã€‚\n\n"
            "### `## ğŸ“ˆ ãƒãƒ¼ã‚±ãƒƒãƒˆ`\n"
            "æŠ•è³‡å®¶å‘ã‘ã€‚å…·ä½“çš„ãªæ•°å­—ï¼ˆé‡‘åˆ©ãƒ»æŒ‡æ•°ãƒ»ç‚ºæ›¿ç­‰ï¼‰ã‚’å«ã‚ã‚‹ã€‚\n\n"
            "### `## ğŸ”® ä»Šå¾Œã®æ³¨ç›®`\n"
            "ç›´è¿‘ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ»äºˆæ¸¬ã‚’2ã€œ3ç‚¹ã€‚\n\n"
            "## ãƒ«ãƒ¼ãƒ«\n"
            "- è¨˜äº‹æœ¬æ–‡ã®å†…å®¹ã‚’è¸ã¾ãˆã¦æ›¸ãï¼ˆRSSæ¦‚è¦ã ã‘ã«é ¼ã‚‰ãªã„ï¼‰\n"
            "- äº‹å®Ÿã®ç¾…åˆ—ã§ã¯ãªãã€Œã ã‹ã‚‰ä½•ï¼Ÿã€ã‚’å¸¸ã«æ„è­˜ã™ã‚‹\n"
            "- è¤‡æ•°è¨˜äº‹ã‚’æ¨ªæ–­çš„ã«çµã³ã¤ã‘ã¦ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æŠ½å‡ºã™ã‚‹\n"
            "- ç…½ã‚Šã‚„æ„Ÿæƒ…çš„ãªè¡¨ç¾ã¯é¿ã‘ã‚‹\n"
            "- å†’é ­ã®æŒ¨æ‹¶æ–‡ã‚„æœ«å°¾ã®ç· ã‚æ–‡ã¯ä¸è¦ã€‚ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã ã‘ã‚’å‡ºåŠ›ã™ã‚‹\n"
            "- æŠ€è¡“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å…ˆã«ã€æŠ•è³‡ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯å¾Œã«é…ç½®ã™ã‚‹\n\n"
            f"## å³é¸è¨˜äº‹ï¼ˆ{len(selected)}ä»¶ãƒ»æœ¬æ–‡ä»˜ãï¼‰\n\n"
            f"{enriched_text}"
        )
        logger.info("Stage 2: generating briefing with enriched content")
        return self._call_gemini(prompt)


def generate_briefing(articles: list[Article], api_key: str | None = None) -> str:
    """Generate a curated briefing. Returns empty string if no API key."""
    if not api_key:
        return ""
    summarizer = GeminiSummarizer(api_key=api_key)
    result = summarizer.generate_briefing(articles)
    return result or ""


def get_summarizer(api_key: str | None = None) -> Summarizer:
    """Factory: returns GeminiSummarizer if API key is available, else Passthrough."""
    if api_key:
        return GeminiSummarizer(api_key=api_key)
    return PassthroughSummarizer()
